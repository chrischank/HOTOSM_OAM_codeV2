Hardware,Nvidia GeForce 1070 Ti 8GB,,,,,,,,,
Dimensions,512 * 512 * 0.1,,256 * 256 * 0.15,,,,,,,
Batch_size_limit,"[6, 8]",,[32],,,,,,,
Train_data(BASE),2368,,4110,,,,,,,
Train_data(AUG),9472,,16440,,,,,,,
Val_data,1184,,2054,,,,,,,
Optimiser,Adam,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
Date,Four_Unet(Vanilla),,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
Date,EB1-Unet(ImageNet),batch_size,pixel_size,window,lr,wd,Scheduler,mean_Dice,mean_IoU,Comment
2022-03-19,9472:1184oc1_EB1-UNet_lr1e-4_wd1e-5_b8_ep500_BCE_RLRONPLATEAU,6,0.1,512,0.0001,0.00001,ReduceLRonPlateau,5.536,0,"The train Val Test of this run were saved, however the copy result became 7348 Train and 1039 Val"
2022-03-22,16440:2054_256oc1_EB1-Unet-IMN_lr1e-3_wd1e-5_b32_ep500_BCE_RLRONPLATEAU(min1e-8),32,0.15,256,1.00E-03,1.00E-05,ReduceLRonPlateau(min1e-8),5.47,0,"First run on 32 batch_size with 256 by 256 by 0.15. This has a much larger Train Val set, picking up bad roofs in Dzaleka quite well, but not confident"
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
,,,,,,,,,,
Date,EB1-Unet(qubvel),,,,,,,,,
