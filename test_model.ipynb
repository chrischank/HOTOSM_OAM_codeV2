{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2492f4f0-d5b8-48ed-bd27-e42b69d62c6d",
   "metadata": {},
   "source": [
    "# Inspect pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7459537d-d913-4f4b-bd41-6a73b3d31e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import dis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from Networks import Five_UNet\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27705ef5-4c11-4ab6-8136-7153c786e6e9",
   "metadata": {},
   "source": [
    "## Binary segmentation (single class)\n",
    "- U-net\n",
    "- fcn_resnet50\n",
    "\n",
    "## Object detection (multi-class)\n",
    "- fasterrcnn_resnet50_fpn\n",
    "- efficientdet b0 - b3\n",
    "\n",
    "## Instance segmentation (multi-class)\n",
    "- maskrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b07f3f-2800-4f6b-9f04-92196d5006d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512, 3])\n",
      "torch.Size([3, 512, 512, 10])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([10, 3, 512, 512])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAEWCAYAAACnuGhyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZnElEQVR4nO3de7xWVZ3H8c9XEEkxUVAHgUSULGrMeHnBdGa8ZCpmOg2ZyYzIqDTdJseahKkpK5vRuZSa0wUviXcwbWAML3irxhJFvEsqFgwQihdA0zTR3/yx19HnHJ5zzj6wnuc8G77v1+t5nb3Xvv2eA/xYa+2111ZEYGaWw2a9HYCZbTycUMwsGycUM8vGCcXMsnFCMbNsnFDMLBsnlBYi6RJJZ6blP5P0WMZz3yBpYlo+UdL/Zjz3BEk35zpfD667v6QnJP1e0jE9PDbL71fSHZJO3tDzbCycUFpURPwiInbvbj9JZ0i6vMT5joiI6Rsal6QRkkJS35pzXxERH9rQc6+HbwDnR8SAiPjvnhxY9vdrPeOEspFTYWP9c94ZeKS3g7C3bKx/0SpB0vslLZD0oqQZQP+abQdKWlazfrqk5WnfxyQdIulw4J+Aj6dq/wNp3zskfUvSncDLwMg6VXNJOl/SGkm/lnRIzYbFkj5Ys15bC/p5+rk6XXO/jk0oSR+QdE869z2SPlCz7Q5J35R0Z/ouN0sa3MXv6BRJiyQ9L2m2pJ1S+ZPASOB/Uhxb1Dl2saSpkh6VtErSjyT17/j7lbRrOv+YtL6TpGckHZjWx0r6paTVkh5oK69zvd0k/Sx972fTn+kmxQmll0jqB/w3cBmwHXAN8Fed7Ls78Flg74jYGjgMWBwRNwL/AsxI1f731Rz2N8BkYGtgSZ3T7gs8CQwGvgZcJ2m7EqH/efo5MF3zVx1i3Q74KXAeMAj4NvBTSYNqdjsemATsAPQDvtjJ9z4Y+FfgWGBI+h5XA0TErsD/AUelOF7tJN4JFL+vXYF3Al/puENEPAmcDlwuaUvgR8D0iLhD0tD0fc6k+HP6InCtpO3rXOubwM3AtsAw4LudxLTRckLpPWOBzYFzIuK1iPgxcE8n+74ObAGMlrR5RCxO/wi6cklEPBIRayPitTrbV9ZcewbwGHDken6XWkcCT0TEZenaVwG/Bo6q2edHEfF4RPwBmAns2cm5JgAXR8SClDCmAvtJGtGDeM6PiKUR8TzwLeAT9XaKiAuARcA8iuT15bTpr4E5ETEnIt6IiLnAfGBcndO8RtEM2ykiXomIbB3fVeGE0nt2ApZH+6cz69UkiIhFwKnAGcBKSVe3Vf27sLSb7fWu3d05y9iJdb/HEmBozfpTNcsvAwPKnCsifg881+Fc3an9PXT3HS8A3gt8t6bGszPwsdTcWS1pNXAARdLp6EuAgLslPSLpb3sQ50bBCaX3rACGSlJN2Ts62zkiroyIAyj+ggdwdtumzg7p5vr1rv27tPwSsGXNtj/pwXl/l2Ks9Q5geTfHdXsuSVtRNKN6cq7hHeL4Xb2dJA0AzgEuAs6oaf4tBS6LiIE1n60i4qyO54iIpyLilIjYCfgk8D1Ju/Ug1spzQuk9vwLWAn8vaXNJHwX2qbejpN0lHZw6Hl8B/gC8kTY/DYxYjzs5O9Rc+2PAu4E5adv9wHFp217A+JrjnknXHtnJeecA75R0vKS+kj4OjAau72F8AFcBkyTtmb77vwDzImJxD87xGUnDUoL4MtBZR+m5wPyIOJmiz+QHqfxy4ChJh0nqI6l/6tAd1vEEkj5WU76KIvm+0XG/jZkTSi+JiD8CHwVOBJ4HPg5c18nuWwBnAc9SNBd2oOhPgKIzF+A5SQt6EMI8YFQ657eA8RHxXNr2zxSdmKuArwNX1sT9ctr/ztQEGNvhez0HfBj4AkXz5EvAhyPi2R7E1nauW1Is11LU6HYFjuvhaa6k6Cj9DUUn9Jkdd5B0NHA48KlUdBowRtKEiFgKHE1xN+0ZihrLP1L/387ewDxJvwdmA5+PiN/0MN5KkydYso2VpMXAySkxWRO4hmJm2bRUQpF0uIpBW4skTenteMysZ1qmySOpD/A4cCiwjGJMxici4tFeDczMSmulGso+wKKI+E3qsLyaojPMzCqib/e7NM1Q2g9CWkYxPLxTklqjemW2cXs2Iuo9arCOVkoopUiaTPGMipk1R90R3PW0UkJZTvtRjcOoMyIyIqYB08A1FLNW00p9KPcAoyTtkp7EPY5icJCZVUTL1FAiYq2kzwI3AX0onjL15DlmFdIyt43Xh5s8Zk1xb0TsVWbHVmrymFnFOaGYWTZOKGaWjROKmWXjhGJm2TihmFk2Tihmlo0Tipll44RiZtk4oZhZNk4oZpaNE4qZZeOEYmbZOKGYWTZOKGaWjROKmWXjhGJm2TihmFk2Tihmlo0Tipll44RiZtk4oZhZNk4oZpaNE4qZZeOEYmbZOKGYWTZOKGaWjROKmWXjhGJm2TihmFk2Tihmlo0Tipll44RiZtk4oZhZNg1LKJIulrRS0sM1ZdtJmivpifRz21QuSedJWiTpQUljGhWXmTVOI2solwCHdyibAtwaEaOAW9M6wBHAqPSZDHy/gXGZWYM0LKFExM+B5zsUHw1MT8vTgWNqyi+Nwl3AQElDGhWbmTVGs/tQdoyIFWn5KWDHtDwUWFqz37JUtg5JkyXNlzS/cWGa2fro21sXjoiQFOtx3DRgGsD6HG9mjdPsGsrTbU2Z9HNlKl8ODK/Zb1gqM7MKaXZCmQ1MTMsTgVk15Sekuz1jgTU1TSMzq4iGNXkkXQUcCAyWtAz4GnAWMFPSScAS4Ni0+xxgHLAIeBmY1Ki4zKxxFFHdbgj3oZg1xb0RsVeZHT1S1syycUIxs2ycUMwsGycUM8vGCcXMsnFCMbNsnFDMLBsnFDPLxgnFzLJxQjGzbJxQzCwbJxQzy8YJxcyycUIxs2ycUMwsGycUM8um24Qi6TpJR0py8jGzLpVJEt8DjgeekHSWpN0bHJOZVVS3CSUibomICcAYYDFwi6RfSpokafNGB2hm1VGqGSNpEHAicDJwH3AuRYKZ27DIzKxyup31XtJPgN2By4Cjal5vMcNv7zOzWmVeo3FeRNxeb0PZmbDNbNNQpskzWtLAthVJ20r6dONCMrOqKpNQTomI1W0rEbEKOKVhEZlZZZVJKH0kqW1FUh+gX+NCMrOqKtOHciNFB+wP0/onU5mZWTvdvoo0jZD9JHBIKpoLXBgRrzc4tm75VaRmTVH6VaR+t7GZdad0QikzDmV/4Axg57S/gIiIkRsSoZltfMr0oVwE/ANwL9DrzRwza11lEsqaiLih4ZGYWeWVSSi3S/p34Drg1bbCiFjQsKjMrJLKJJR908/aTpkADs4fjplVWbcJJSIOWp8TSxoOXArsSJGApkXEuZK2A2YAIyimQzg2IlalwXPnAuOAl4ETXQsyq5YyM7btKOkiSTek9dGSTipx7rXAFyJiNDAW+Iyk0cAU4NaIGAXcmtYBjgBGpc9k4Ps9/jZm1qvKDL2/BLgJ2CmtPw6c2t1BEbGirYYRES8CC4GhwNHA9LTbdOCYtHw0cGkU7gIGShpS6luYWUsok1AGR8RM4A2AiFhLD28fSxoBvB+YB+xYM6fKUxRNIiiSzdKaw5alMjOriDKdsi+lGdsCQNJYYE3ZC0gaAFwLnBoRL9Q8Z0hERE9Hu0qaTNEkMrMWUyahnAbMBnaVdCewPTC+zMnTnLPXAldExHWp+GlJQyJiRWrSrEzly4HhNYcPS2XtRMQ0YFo6v4fem7WQMpNULwD+AvgAxUOC74mIB7s7Lt21uQhYGBHfrtk0G5iYlicCs2rKT1BhLMWAuhWYWWWUedr4hHrlEXFpN8cdAPwCeIjU/wL8E0U/ykzgHcASitvGz6cEdD5wOMVt40kR0eWcta6hmDVFvqeNJX23ZrU/xTQGCyKiVLOnkZxQzJoi39PGEfG52vU0v+zV6xeXmW3M1uf1oi8Bu+QOxMyqr8x8KP9DumVMkYBGU/SBmJm1U+a28X/ULK8FlkTEsgbFY2YVVqYP5WfNCMTMqq9Mk+dF3mrytNtEMdj17dmjMrNKKtPkOQdYQfFuYwETgCER8dUGxmVmFVRmHMoDEfG+7sp6g8ehmDVF6XEoZW4bvyRpgqQ+kjaTNIHi1rGZWTtlEsrxwLHA0+nzsVRmZtaOX/RlZt3J1+SR9E5Jt0p6OK3vIekrGxqhmW18yjR5LgCmAq8BpKkLjmtkUGZWTWUSypYRcXeHsrWNCMbMqq1MQnlW0q68NQXkeIpxKWZm7ZQZ2PYZiikX3yVpOfBbisFtZmbtdJlQJPUBPh0RH5S0FbBZeiWGmdk6ukwoEfF6msqRiPBgNjPrUpkmz32SZgPXUDNCtmYWezMzoFxC6Q88R/uXowfghGJm7XSaUCSdHRGnA3Mi4pomxmRmFdXVbeNx6dUWU5sVjJlVW1dNnhuBVcAASS/UlHtiJTOrq8x8KLMi4ugmxdMjfjjQrCnyPRzYqsnEzFrP+ryXx8ysLicUM8umVEKR9DZJuzc6GDOrtjITLB0F3E9x1wdJe6aRs2Zm7ZSpoZwB7AOsBoiI+/G7jc2sjjIJ5bWIWNOhzLdrzWwdZZ7leUTS8UAfSaOAvwd+2diwzKyKytRQPge8B3gVuBJYA5zawJjMrKLKjJQdExELmhRPj3ikrFlTZH1z4H9KWijpm5LeWzYCSf0l3S3pAUmPSPp6Kt9F0jxJiyTNkNQvlW+R1hel7SPKXsvMWkOZofcHAQcBzwA/lPRQyffyvAocnN6BvCdwuKSxwNnAdyJiN4qHD09K+58ErErl30n7mVmVRETpD/CnwGXAH3t43JbAAmBf4FmgbyrfD7gpLd8E7JeW+6b91M15wx9//Gn4Z37Zf+tlBra9W9IZkh4Cvktxh2dYd8elY/tIuh9YCcwFngRWR0Tbe32WAUPT8lBgKUDavgYYVOeckyXNlzS/TAxm1jxlbhtfDMwADouI3/Xk5BHxOrCnpIHAT4B39TjCdc85jeK1Hu6UNWsx3SaUiNhvQy8SEasl3U7RxBkoqW+qhQwDlqfdlgPDgWWS+gLbUMxla2YV0WmTR9LM9PMhSQ/WfB6S9GB3J5a0faqZIOltwKHAQuB2YHzabSIwKy3PTuuk7bdFd/e0zayldDoORdKQiFghaed62yNiSZcnlvYApgN9KBLXzIj4hqSRwNXAdsB9wF9HxKuS+lN0+L4feB44LiJ+0801nHDMGq/0OJQyA9vaZr/vsqw3OKGYNUXWgW2H1ik7omfxmNmmoKv38nwK+DQwskOfydbAnY0OzMyqp6s+lG2AbYF/BabUbHoxIp5vQmzdcpPHrCny9aG8uaO0A8VrSQGIiP9bv9jycUIxa4p8fSiSjpL0BPBb4GfAYuCGDQrPzDZKZTplzwTGAo9HxC7AIcBdDY3KzCqp7BSQzwGbSdosIm4HSlV/zGzTUuZZntWSBgA/B66QtBJ4qbFhmVkVlRnYthXwCsVL0idQPGNzRaq19Cp3ypo1RelO2TIPB9bWRqavd0hmttHramDbixSTq7xZlNYFRES8vcGxmVnFdJpQImLrZgZiZtVX9t3GB0ialJYHS/KbA81sHWUGtn0NOB2Ymor6AZc3Migzq6YyNZS/BD5CulWcpoF0c8jM1lEmofwxzZwW8OZtZDOzdZRJKDMl/ZBiLthTgFuACxoblplVUZfjUCSJYsb7dwEvALsDX42IuU2IzcwqpsuEEhEhaU5E/CnFe3XMzDpVpsmzQNLeDY/EzCqvzMOB+wITJC2huNPTNlJ2j4ZGZmaVUyahHNbwKMxso1Dm4cAu379jZtam1NB7M7MynFDMLBsnFDPLxgnFzLJxQjGzbJxQzCwbJxQzy8YJxcyycUIxs2ycUMwsm4YnFEl9JN0n6fq0voukeZIWSZohqV8q3yKtL0rbRzQ6NjPLqxk1lM8DC2vWzwa+ExG7AauAk1L5ScCqVP6dtJ+ZVUhDE4qkYcCRwIVpXcDBwI/TLtOBY9Ly0bz1ZsIfA4ek/c2sIhpdQzkH+BLwRlofBKyOiLVpfRkwNC0PBZYCpO1r0v7tSJosab6k+Q2M28zWQ8MSiqQPAysj4t6c542IaRGxV9mXN5tZ85SZYGl97Q98RNI4oD/wduBcitnz+6ZayDBgedp/OTAcWCapL7AN8FwD4zOzzBpWQ4mIqRExLCJGAMcBt0XEBOB2YHzabSIwKy3PTuuk7bel9wGZWUX0xjiU04HTJC2i6CO5KJVfBAxK5acBU3ohNjPbAKpyJUBSdYM3q457y/ZZeqSsmWXjhGJm2TihmFk2Tihmlo0Tipll44RiZtk4oZhZNk4oZpaNE4qZZeOEYmbZOKGYWTZOKGaWjROKmWXjhGJm2TihmFk2Tihmlo0Tipll44RiZtk4oZhZNk4oZpaNE4qZZeOEYmbZOKGYWTZOKGaWjROKmWXjhGJm2TihmFk2Tihmlo0Tipll44RiZtk4oZhZNk4oZpaNE4qZZeOEYmbZNDShSFos6SFJ90uan8q2kzRX0hPp57apXJLOk7RI0oOSxjQyNjPLrxk1lIMiYs+I2CutTwFujYhRwK1pHeAIYFT6TAa+34TYzCyj3mjyHA1MT8vTgWNqyi+Nwl3AQElDeiE+M1tPjU4oAdws6V5Jk1PZjhGxIi0/BeyYlocCS2uOXZbK2pE0WdL8tiaUmbWOvg0+/wERsVzSDsBcSb+u3RgRISl6csKImAZMA+jpsWbWWA2toUTE8vRzJfATYB/g6bamTPq5Mu2+HBhec/iwVGZmFdGwhCJpK0lbty0DHwIeBmYDE9NuE4FZaXk2cEK62zMWWFPTNDKzCmhkk2dH4CeS2q5zZUTcKOkeYKakk4AlwLFp/znAOGAR8DIwqYGxmVkDKKK63RCSXgQe6+04ShoMPNvbQZRQlTihOrFWJU6oH+vOEbF9mYMb3SnbaI/VjG9paZLmVyHWqsQJ1Ym1KnHChsfqofdmlo0TipllU/WEMq23A+iBqsRalTihOrFWJU7YwFgr3SlrZq2l6jUUM2shTihmlk1lE4qkwyU9luZPmdL9EQ2N5WJJKyU9XFPWkvO+SBou6XZJj0p6RNLnWzFeSf0l3S3pgRTn11P5LpLmpXhmSOqXyrdI64vS9hHNiLMm3j6S7pN0fYvH2dg5iiKich+gD/AkMBLoBzwAjO7FeP4cGAM8XFP2b8CUtDwFODstjwNuAASMBeY1OdYhwJi0vDXwODC61eJN1xuQljcH5qXrzwSOS+U/AD6Vlj8N/CAtHwfMaPLv9TTgSuD6tN6qcS4GBncoy/Zn37QvkvmXsh9wU836VGBqL8c0okNCeQwYkpaHUAzCA/gh8Il6+/VS3LOAQ1s5XmBLYAGwL8Uozr4d/x4ANwH7peW+aT81Kb5hFJOFHQxcn/4Btlyc6Zr1Ekq2P/uqNnlKzZ3SyzZo3pdmSNXt91P8799y8aZmxP0UT6TPpaiVro6ItXVieTPOtH0NMKgZcQLnAF8C3kjrg1o0TmjAHEW1qj70vhIiej7vS6NJGgBcC5waES+khziB1ok3Il4H9pQ0kGL6i3f1bkTrkvRhYGVE3CvpwF4Op4zscxTVqmoNpQpzp7TsvC+SNqdIJldExHWpuGXjjYjVwO0UTYeBktr+I6yN5c040/ZtgOeaEN7+wEckLQaupmj2nNuCcQKNn6OoqgnlHmBU6knvR9G5NbuXY+qoJed9UVEVuQhYGBHfbtV4JW2faiZIehtFP89CisQyvpM42+IfD9wWqeHfSBExNSKGRcQIir+Ht0XEhFaLE5o0R1GzOoMa0Lk0juIOxZPAl3s5lquAFcBrFO3MkyjaxbcCTwC3ANulfQX8V4r7IWCvJsd6AEU7+kHg/vQZ12rxAnsA96U4Hwa+mspHAndTzJtzDbBFKu+f1hel7SN74e/Bgbx1l6fl4kwxPZA+j7T9u8n5Z++h92aWTVWbPGbWgpxQzCwbJxQzy8YJxcyycUIxs2ycUGwdki6UNHo9jhuhmieuN+D6Wc5jzeeh97aOiDi5t2OwanINZROVagG/lnSFpIWSfixpy7TtDkl7Sdo5zZExWNJmkn4h6UPpob1/l3RPmifjk91c62pJR9asXyJpfIrhF5IWpM8H6hx7oqTza9avb3tmJsXyq3TsNen5JCSdpWK+lwcl/Uee35iV4YSyadsd+F5EvBt4gWKujjdFxBLgbOD7wBeARyPiZoqRwGsiYm9gb+AUSbt0cZ0ZpDdEpkclDgF+SvHMyKERMQb4OHBe2cAlDQa+AnwwHT8fOE3SIOAvgfdExB7AmWXPaRvOCWXTtjQi7kzLl1MMy28nIi4E3g78HfDFVPwhimc87qeY+mAQMKqL69wAHCRpC+AI4OcR8QeKiZMukPQQxXD0nvTbjE3735nimAjsTDEdwCvARZI+SvFaW2sS96Fs2jo+d7HOcxipGTQsrQ4AXqR4xuNzEXFTh31H1L1IxCuS7gAOo6iJXJ02/QPwNPA+iv/cXqlz+Fra/8fXv+1ywNyI+ESdmPehqAWNBz5L8QSwNYFrKJu2d0jaLy0fD/xvnX3OBq4AvgpckMpuAj6VpkFA0jvT06tdmQFMAv4MuDGVbQOsiIg3gL+hmNqzo8UUc6JsJmk4xeP2AHcB+0vaLcWwVYpjALBNRMyhSFjv6yYuy8g1lE3bY8BnJF0MPErRV/ImSX9B0Ueyf0S8LumvJE0CLqSY8nJBmg7hGeCYbq51M3AZMCsi/pjKvgdcK+kEiiTzUp3j7gR+m+JbSDEVJBHxjKQTgatSUwqKPpUXgVmS+lPUYk4r8XuwTPy08SYqNU+uj4j39nYstvFwk8fMsnENxcyycQ3FzLJxQjGzbJxQzCwbJxQzy8YJxcyy+X/b48Tv9ky7hgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/\")\n",
    "\n",
    "DZK = []\n",
    "\n",
    "for root, path, filename in os.walk(os.path.join(data_path, \"td_DZK\", \"IMG/\")):\n",
    "    for i in filename:\n",
    "        if i.endswith(\".png\"):\n",
    "            to_tensor = transforms.ToTensor()\n",
    "            \n",
    "            with Image.open(root + i) as img:\n",
    "                img = to_tensor(img)\n",
    "                DZK.append(img)\n",
    "\n",
    "# plot the pixel values\n",
    "#img_np = np.array(DZK[3])\n",
    "#plt.hist(img_np.ravel(), bins=50, density=True)\n",
    "#plt.xlabel(\"pixel values\")\n",
    "#plt.ylabel(\"relative frequency\")\n",
    "#plt.title(\"distribution of pixels\")                \n",
    "\n",
    "test = DZK[4].permute(1, 2, 0)\n",
    "print(test.shape)\n",
    "plt.imshow(test)\n",
    "\n",
    "# Calculate mean and std for normalisation\n",
    "# (Channel, Height, Width, Batch)\n",
    "imgs = torch.stack(DZK, dim = 3)\n",
    "print(imgs.shape)\n",
    "\n",
    "mean = imgs.view(3, -1).mean(dim = 1)\n",
    "std = imgs.view(3, -1).std(dim = 1)\n",
    "\n",
    "# Reset DZK list\n",
    "DZK = []\n",
    "\n",
    "for root, path, filename in os.walk(os.path.join(data_path, \"td_DZK\", \"IMG/\")):\n",
    "    for i in filename:\n",
    "        if i.endswith(\".png\"):\n",
    "            to_tensor = transforms.ToTensor()\n",
    "            \n",
    "            with Image.open(root + i) as img:\n",
    "                img = to_tensor(img)\n",
    "                DZK.append(img)\n",
    "                print(img.shape)\n",
    "\n",
    "# plot the pixel values\n",
    "img_np = np.array(DZK[8])\n",
    "plt.hist(img_np.ravel(), bins=50, density=True)\n",
    "plt.xlabel(\"pixel values\")\n",
    "plt.ylabel(\"relative frequency\")\n",
    "plt.title(\"distribution of pixels\")\n",
    "                \n",
    "# (Batch, Channel, Height, Width) format == nn.Conv2d()                \n",
    "imgs = torch.stack(DZK, dim = 0)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2604ef9d-9238-46c7-aa9d-8b98936feef2",
   "metadata": {},
   "source": [
    "DZK = []\n",
    "\n",
    "for root, path, filename in os.walk(os.path.join(data_path, \"td_DZK\", \"IMG/\")):\n",
    "    for i in filename:\n",
    "        if i.endswith(\".png\"):\n",
    "            to_tensor = transforms.ToTensor()\n",
    "            \n",
    "            with Image.open(root + i) as img:\n",
    "                img = to_tensor(img)\n",
    "                DZK.append(img)\n",
    "\n",
    "# plot the pixel values\n",
    "#img_np = np.array(DZK[3])\n",
    "#plt.hist(img_np.ravel(), bins=50, density=True)\n",
    "#plt.xlabel(\"pixel values\")\n",
    "#plt.ylabel(\"relative frequency\")\n",
    "#plt.title(\"distribution of pixels\")                \n",
    "\n",
    "print(test.shape)\n",
    "test = DZK[4].permute(1, 2, 0)\n",
    "plt.imshow(test)\n",
    "\n",
    "# Calculate mean and std for normalisation\n",
    "# (Channel, Height, Width, Batch)\n",
    "imgs = torch.stack(DZK, dim = 3)\n",
    "print(imgs.shape)\n",
    "\n",
    "mean = imgs.view(3, -1).mean(dim = 1)\n",
    "std = imgs.view(3, -1).std(dim = 1)\n",
    "### Binary segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b665b216-2ba1-4be7-8227-91c4baa89b01",
   "metadata": {},
   "source": [
    "## Chris custom 5 layer U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9379dfa6-b938-4f17-ab77-21ec0f8b5184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23496066\n"
     ]
    }
   ],
   "source": [
    "# Chris' 5 layer U_Net\n",
    "Five_UNet = Five_UNet()\n",
    "\n",
    "print(sum(p.numel() for p in Five_UNet.parameters() if p.requires_grad == True))\n",
    "#print(Five_UNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58551e-8735-40a7-abf3-2abb60ab7805",
   "metadata": {},
   "source": [
    "### Mateuszbuda classic U_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c7cb83-4aae-408a-933d-a72d8aaa8406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/chris/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7763041\n",
      "tensor([[[[5.5781e-06, 4.7937e-06, 8.4292e-06,  ..., 1.6734e-06,\n",
      "           7.2109e-07, 3.1599e-06],\n",
      "          [6.2059e-06, 3.3786e-06, 9.0324e-06,  ..., 5.2748e-07,\n",
      "           2.6459e-07, 1.2898e-06],\n",
      "          [6.4884e-06, 2.5493e-05, 6.4062e-06,  ..., 2.4354e-07,\n",
      "           1.1083e-07, 4.5566e-07],\n",
      "          ...,\n",
      "          [7.6218e-06, 1.5540e-05, 2.2886e-05,  ..., 1.0981e-06,\n",
      "           3.2117e-07, 5.2226e-07],\n",
      "          [1.3021e-05, 1.9110e-05, 1.3582e-05,  ..., 1.5786e-06,\n",
      "           3.0391e-07, 1.0297e-06],\n",
      "          [4.3103e-06, 4.2378e-06, 4.0916e-06,  ..., 2.5784e-06,\n",
      "           1.7760e-06, 2.6084e-06]]]], grad_fn=<SigmoidBackward>)\n",
      "37451\n"
     ]
    }
   ],
   "source": [
    "# Inspect U-Net (not native torchvision, but torch.hub)\n",
    "brain_UNet = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', \n",
    "                  in_channels = 3, out_channels = 1, init_features = 32, pretrained=True)\n",
    "\n",
    "print(sum(p.numel() for p in brain_UNet.parameters() if p.requires_grad == True))\n",
    "#print(brain_UNet)\n",
    "\n",
    "# Pass the image through\n",
    "img_t = DZK[8]\n",
    "prediction = brain_UNet(img_t.unsqueeze(0))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "predicted_class = prediction.detach().numpy()\n",
    "print(np.argmax(predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069458f-e390-4208-a3e4-b355ad65ea18",
   "metadata": {},
   "source": [
    "### Qubvel OpenCities U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331402e5-43cb-4013-b022-b409ce7e4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8757105\n"
     ]
    }
   ],
   "source": [
    "effb1_UNet = smp.Unet(encoder_name='efficientnet-b1', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=1, activation=\"softmax\", aux_params=None)\n",
    "\n",
    "qubvel_weights = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/qubvel_UNet/weights/stage3/effb1-f0/checkpoints/best.pth\")\n",
    "qubvel_weights = torch.load(qubvel_weights, map_location = device)\n",
    "effb1_UNet.load_state_dict(qubvel_weights[\"state_dict\"])\n",
    "\n",
    "print(sum(p.numel() for p in effb1_UNet.parameters() if p.requires_grad == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcbf5633-4791-426f-aeee-412753ae5dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'segmentation_models_pytorch.decoders.unet.model.Unet'>\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(type(effb1_UNet))\n",
    "\n",
    "test = dis.dis(effb1_UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca362bbd-b92b-41af-83e0-93868dbfc54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]], grad_fn=<SoftmaxBackward>)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/HOTOSM_cpu/lib/python3.8/site-packages/segmentation_models_pytorch/base/modules.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n"
     ]
    }
   ],
   "source": [
    "effb1_UNet.eval()\n",
    "\n",
    "# Pass the image through\n",
    "img_t = DZK[8]\n",
    "prediction = effb1_UNet(img_t.unsqueeze(0))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "predicted_class = prediction.detach().numpy()\n",
    "print(np.argmax(predicted_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
