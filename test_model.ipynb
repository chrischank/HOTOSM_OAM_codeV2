{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2492f4f0-d5b8-48ed-bd27-e42b69d62c6d",
   "metadata": {},
   "source": [
    "# Test pretrained model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004e562",
   "metadata": {},
   "source": [
    "ATTENTION!!! Run the qubvel pretrained Network in a separate conda environment with:\n",
    "- torch==1.1.0\n",
    "- python >=3.7,<3.8\n",
    "- for details read qubvel_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7459537d-d913-4f4b-bd41-6a73b3d31e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from Networks import Five_UNet\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b07f3f-2800-4f6b-9f04-92196d5006d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512, 3])\n",
      "torch.Size([3, 512, 512, 10])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([3, 512, 512])\n",
      "torch.Size([10, 3, 512, 512])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/\")\n",
    "\n",
    "DZK = []\n",
    "\n",
    "for root, path, filename in os.walk(os.path.join(data_path, \"td_DZK\", \"IMG/\")):\n",
    "    for i in filename:\n",
    "        if i.endswith(\".png\"):\n",
    "            to_tensor = transforms.ToTensor()\n",
    "            \n",
    "            with Image.open(root + i) as img:\n",
    "                img = to_tensor(img)\n",
    "                DZK.append(img)\n",
    "\n",
    "# plot the pixel values\n",
    "#img_np = np.array(DZK[3])\n",
    "#plt.hist(img_np.ravel(), bins=50, density=True)\n",
    "#plt.xlabel(\"pixel values\")\n",
    "#plt.ylabel(\"relative frequency\")\n",
    "#plt.title(\"distribution of pixels\")                \n",
    "\n",
    "test = DZK[4].permute(1, 2, 0)\n",
    "print(test.shape)\n",
    "plt.imshow(test)\n",
    "\n",
    "# Calculate mean and std for normalisation\n",
    "# (Channel, Height, Width, Batch)\n",
    "imgs = torch.stack(DZK, dim = 3)\n",
    "print(imgs.shape)\n",
    "\n",
    "mean = imgs.view(3, -1).mean(dim = 1)\n",
    "std = imgs.view(3, -1).std(dim = 1)\n",
    "\n",
    "# Reset DZK list\n",
    "DZK = []\n",
    "\n",
    "for root, path, filename in os.walk(os.path.join(data_path, \"td_DZK\", \"IMG/\")):\n",
    "    for i in filename:\n",
    "        if i.endswith(\".png\"):\n",
    "            to_tensor = transforms.ToTensor()\n",
    "            \n",
    "            with Image.open(root + i) as img:\n",
    "                img = to_tensor(img)\n",
    "                DZK.append(img)\n",
    "                print(img.shape)\n",
    "\n",
    "# plot the pixel values\n",
    "img_np = np.array(DZK[8])\n",
    "plt.hist(img_np.ravel(), bins=50, density=True)\n",
    "plt.xlabel(\"pixel values\")\n",
    "plt.ylabel(\"relative frequency\")\n",
    "plt.title(\"distribution of pixels\")\n",
    "                \n",
    "# (Batch, Channel, Height, Width) format == nn.Conv2d()                \n",
    "imgs = torch.stack(DZK, dim = 0)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b665b216-2ba1-4be7-8227-91c4baa89b01",
   "metadata": {},
   "source": [
    "## Chris custom 5 layer U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9379dfa6-b938-4f17-ab77-21ec0f8b5184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23496066\n"
     ]
    }
   ],
   "source": [
    "# Chris' 5 layer U_Net\n",
    "Five_UNet = Five_UNet()\n",
    "\n",
    "print(sum(p.numel() for p in Five_UNet.parameters() if p.requires_grad == True))\n",
    "#print(Five_UNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58551e-8735-40a7-abf3-2abb60ab7805",
   "metadata": {},
   "source": [
    "### Mateuszbuda classic U_Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c7cb83-4aae-408a-933d-a72d8aaa8406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/chris/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n",
      "Downloading: \"https://github.com/mateuszbuda/brain-segmentation-pytorch/releases/download/v1.0/unet-e012d006.pt\" to /home/chris/.cache/torch/checkpoints/unet-e012d006.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7763041\n",
      "tensor([[[[5.5781e-06, 4.7937e-06, 8.4292e-06,  ..., 1.6734e-06,\n",
      "           7.2109e-07, 3.1599e-06],\n",
      "          [6.2059e-06, 3.3786e-06, 9.0324e-06,  ..., 5.2748e-07,\n",
      "           2.6459e-07, 1.2898e-06],\n",
      "          [6.4884e-06, 2.5493e-05, 6.4062e-06,  ..., 2.4354e-07,\n",
      "           1.1083e-07, 4.5566e-07],\n",
      "          ...,\n",
      "          [7.6218e-06, 1.5540e-05, 2.2886e-05,  ..., 1.0981e-06,\n",
      "           3.2117e-07, 5.2226e-07],\n",
      "          [1.3021e-05, 1.9110e-05, 1.3582e-05,  ..., 1.5786e-06,\n",
      "           3.0391e-07, 1.0297e-06],\n",
      "          [4.3103e-06, 4.2378e-06, 4.0916e-06,  ..., 2.5784e-06,\n",
      "           1.7760e-06, 2.6084e-06]]]], grad_fn=<SigmoidBackward>)\n",
      "37451\n"
     ]
    }
   ],
   "source": [
    "# Inspect U-Net (not native torchvision, but torch.hub)\n",
    "brain_UNet = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', \n",
    "                  in_channels = 3, out_channels = 1, init_features = 32, pretrained=True)\n",
    "\n",
    "print(sum(p.numel() for p in brain_UNet.parameters() if p.requires_grad == True))\n",
    "#print(brain_UNet)\n",
    "\n",
    "# Pass the image through\n",
    "img_t = DZK[8]\n",
    "prediction = brain_UNet(img_t.unsqueeze(0))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "predicted_class = prediction.detach().numpy()\n",
    "print(np.argmax(predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069458f-e390-4208-a3e4-b355ad65ea18",
   "metadata": {},
   "source": [
    "### Qubvel OpenCities U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331402e5-43cb-4013-b022-b409ce7e4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8757105\n"
     ]
    }
   ],
   "source": [
    "effb1_UNet = smp.Unet(encoder_name='efficientnet-b1', encoder_depth=5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=1, activation=\"softmax\", aux_params=None)\n",
    "\n",
    "qubvel_weights = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/qubvel_UNet/weights/stage3/effb1-f0/checkpoints/best.pth\")\n",
    "qubvel_weights = torch.load(qubvel_weights, map_location = device)\n",
    "effb1_UNet.load_state_dict(qubvel_weights[\"state_dict\"])\n",
    "\n",
    "print(sum(p.numel() for p in effb1_UNet.parameters() if p.requires_grad == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbf5633-4791-426f-aeee-412753ae5dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'segmentation_models_pytorch.unet.model.Unet'>\n"
     ]
    }
   ],
   "source": [
    "print(type(effb1_UNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca362bbd-b92b-41af-83e0-93868dbfc54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]], grad_fn=<SoftmaxBackward>)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/qubvel3.7_cpu/lib/python3.7/site-packages/segmentation_models_pytorch/base/modules.py:89: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.activation(x)\n"
     ]
    }
   ],
   "source": [
    "effb1_UNet.eval()\n",
    "\n",
    "# Pass the image through\n",
    "img_t = DZK[8]\n",
    "prediction = effb1_UNet(img_t.unsqueeze(0))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "predicted_class = prediction.detach().numpy()\n",
    "print(np.argmax(predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9073a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
