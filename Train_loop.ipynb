{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994b046f-e5e7-48c9-9afd-a510f864b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#Training loop for NNs       #\n",
    "#Maintainer: Christopher Chan#\n",
    "#Version: 0.2.4              #\n",
    "#Date: 2022-03-13            #\n",
    "##############################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pathlib\n",
    "import time\n",
    "import re\n",
    "import PIL\n",
    "import random\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from ray import tune\n",
    "from ray.tune.suggest.bohb import TuneBOHB\n",
    "from ray.tune.schedulers import HyperBandForBOHB\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Networks import Five_UNet, Four_UNet\n",
    "from dataloader import BuildingDataset\n",
    "%matplotlib inline\n",
    "\n",
    "device = (torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "          else torch.device(\"cpu\"))\n",
    "\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "#td_KBYSamp = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY\")\n",
    "#td_DZKSamp = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK\")\n",
    "#td_DZKNSamp = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN\")\n",
    "\n",
    "td_KBY10 = os.path.abspath(\"/home/mnt/HOTOSM_data/Kakuma10cm/Kalobeyei/td_KBY\")\n",
    "td_DZK10 = os.path.abspath(\"/home/mnt/HOTOSM_data/Dzaleka10cm/td_DZK\")\n",
    "td_DZKN10 = os.path.abspath(\"/home/mnt/HOTOSM_data/Dzaleka_N10cm/td_DZKN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98591c8",
   "metadata": {},
   "source": [
    "## Change class label from 2 to 1 for binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff1f48",
   "metadata": {},
   "source": [
    "for root, dirs, filename in os.walk(os.path.join(td_DZK10, \"LBL\")):\n",
    "    for i in filename:\n",
    "        if i.endswith(\".png\"):\n",
    "            png = Image.open(root + \"/\" + i)\n",
    "            px = png.load()\n",
    "\n",
    "            for x in range(png.size[0]):\n",
    "                for y in range(png.size[1]):\n",
    "                    if px[x, y] == 2:\n",
    "                        px[x, y] = 1\n",
    "                        \n",
    "                png.save(root + \"/\" + i, \"PNG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba42bb2-e3e5-4b82-8757-2c591377fa0c",
   "metadata": {},
   "source": [
    "### Train Val Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2cfbd46-14a4-46d0-955c-8bcb85c3d3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images and labels pair in DataLoader: 3947\n",
      "Concatenated TRAINING images and labels pair: 2368 :\n",
      "Concatenated VALIDATION images and labels pair: 1184 :\n",
      "Concatenated TESTING images: 395 and labels pair: 395 :\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Below is a set of relatively complex functions which:\n",
    "# Perform the train, val, test split at a rounded ratio of 62%, 27%, and 10% based on each sets of imagery\n",
    "# This will be followed by first pseudo changing the name of _LBL_ to _IMG_ to match the split imagery\n",
    "# Lastly, once the correct LBL files are matched, \n",
    "\n",
    "def tvt_split(td):\n",
    "    \n",
    "    img_ls = []\n",
    "    \n",
    "    for root, dirs, filename in os.walk(os.path.join(td, \"IMG\")):\n",
    "        for i in filename:\n",
    "            if i.endswith(\".png\"):\n",
    "                img_ls.append(root + \"/\" + i)\n",
    "        \n",
    "        img_ls = BuildingDataset(img_ls, _)\n",
    "        \n",
    "        train_IMG, val_IMG, test_IMG = random_split(img_ls.png_dir, [int(round(0.6 * len(img_ls.png_dir))),\n",
    "                                                                     int(round(0.3 * len(img_ls.png_dir))),\n",
    "                                                                     int(round(0.1 * len(img_ls.png_dir)))])\n",
    "        \n",
    "        return train_IMG, val_IMG, test_IMG\n",
    "\n",
    "DZK_train, DZK_val, DZK_test = tvt_split(td_DZK10)\n",
    "KBY_train, KBY_val, KBY_test = tvt_split(td_KBY10)\n",
    "DZKN_train, DZKN_val, DZKN_test = tvt_split(td_DZK10)\n",
    "\n",
    "##################\n",
    "# TOO COMPLICATED#\n",
    "##################\n",
    "\n",
    "#def match_LBL(td, imgs):\n",
    "#    \n",
    "#    lbl_ls = []\n",
    "#    img_ls = []\n",
    "#    match_ls = []\n",
    "#    \n",
    "#    imgs = list(imgs)\n",
    "#    \n",
    "#    for root, dirs, filename in os.walk(os.path.join(td, \"LBL\")):\n",
    "#        for j in filename:\n",
    "#            if j.endswith(\".png\"):\n",
    "#                ps_name = j.rsplit(\"_LBL_\")[0] + \"_IMG_\" + j.rsplit(\"_LBL_\")[1] # Parse the string, PSEUDO-CHANGE _LBL_ to _IMG_\n",
    "#                lbl_ls.append(ps_name)\n",
    "#    \n",
    "#    for k in imgs:\n",
    "#        names = os.path.basename(k)\n",
    "#        img_ls.append(names)\n",
    "#        \n",
    "#    def common(a, b):\n",
    "#        a_set = set(a)\n",
    "#        b_set = set(b)\n",
    "#        if (a_set & b_set):\n",
    "#            return (a_set & b_set)\n",
    "#        else:\n",
    "#            print(\"No common elements\")\n",
    "#            \n",
    "#            \n",
    "#    match_ls = common(img_ls, lbl_ls)\n",
    "#        \n",
    "#    match_ls = [(root + \"/\" + n.replace(\"_IMG_\", \"_LBL_\")) for n in match_ls] # Change the _IMG_ back to _LBL_\n",
    "#    \n",
    "#    print(\"For the selected dataset of {0}, There are: {1} images, {2} labels, and {3} matching image/label pairs.\".format(os.path.basename(td), len(img_ls), len(lbl_ls), len(match_ls)))\n",
    "#    \n",
    "#    return match_ls\n",
    "\n",
    "#########################################\n",
    "# Assign matched LBL to new LBL datasets#\n",
    "#########################################\n",
    "\n",
    "#DZKLBL_Train = match_LBL(td_DZK, DZK_train)\n",
    "#DZKLBL_Val = match_LBL(td_DZK, DZK_val)\n",
    "#DZKLBL_Test = match_LBL(td_DZK, DZK_test)\n",
    "#DZKNLBL_Train = match_LBL(td_DZKN, DZKN_train)\n",
    "#DZKNLBL_Val = match_LBL(td_DZKN, DZKN_val)\n",
    "#DZKNLBL_Test = match_LBL(td_DZKN, DZKN_test)\n",
    "#KBYLBL_Train = match_LBL(td_KBY, KBY_train)\n",
    "#KBYLBL_Val = match_LBL(td_KBY, KBY_val)\n",
    "#KBYLBL_Test = match_LBL(td_KBY, KBY_test)\n",
    "\n",
    "############\n",
    "# Try again#\n",
    "############\n",
    "\n",
    "TrainLBL_ls = []\n",
    "ValLBL_ls = []\n",
    "TestLBL_ls = []\n",
    "\n",
    "TrainIMG_ls = list(DZK_train + KBY_train + DZKN_train)\n",
    "ValIMG_ls = list(DZK_val + KBY_val + DZKN_val)\n",
    "TestIMG_ls = list(DZK_test + KBY_test + DZKN_test)\n",
    "\n",
    "for i in TrainIMG_ls:\n",
    "    i = re.sub(\"IMG\", \"LBL\", i, count = 2)\n",
    "    TrainLBL_ls.append(i)\n",
    "\n",
    "for i in ValIMG_ls:\n",
    "    i = re.sub(\"IMG\", \"LBL\", i, count = 2)\n",
    "    ValLBL_ls.append(i)\n",
    "\n",
    "for i in TestIMG_ls:\n",
    "    i = re.sub(\"IMG\", \"LBL\", i, count = 2)\n",
    "    TestLBL_ls.append(i)\n",
    "\n",
    "Train = BuildingDataset(png_dir = TrainIMG_ls,\n",
    "                        lbl_dir = TrainLBL_ls)\n",
    "\n",
    "Val = BuildingDataset(png_dir = ValIMG_ls,\n",
    "                      lbl_dir = ValLBL_ls)\n",
    "\n",
    "Test = BuildingDataset(png_dir = TestIMG_ls,\n",
    "                       lbl_dir = TestLBL_ls)\n",
    "\n",
    "assert len(Train.png_dir) == len(Train.lbl_dir)\n",
    "\n",
    "print(\"Total images and labels pair in DataLoader: {0}\".format(len(Train.png_dir) + len(Val.png_dir) + len(Test.png_dir)))\n",
    "\n",
    "print(\"Concatenated TRAINING images and labels pair: {0} :\".format(len(Train.png_dir)))\n",
    "#for x, y in zip(Train.png_dir, Train.lbl_dir):    \n",
    "#    print(f\"Image: {x}\", f\"Label: {y}\")\n",
    "\n",
    "print(\"Concatenated VALIDATION images and labels pair: {0} :\".format(len(Val.png_dir)))\n",
    "#for x, y in zip(Val.png_dir, Val.lbl_dir):\n",
    "#    print(f\"Image: {x}\", f\"Label: {y}\")\n",
    "\n",
    "print(\"Concatenated TESTING images: {0} and labels pair: {0} :\".format(len(Test.png_dir)))\n",
    "#for x, y in zip(Test.png_dir, Test.lbl_dir):\n",
    "#    print(f\"Image: {x}\", f\"Label: {y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c717152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimmed down version\n",
    "def rayHPO_loop(n_epochs, optimizer, model, xp_name,\n",
    "                loss_fn, in_channels, out_channels, train_loader,\n",
    "                checkpoint_freq):\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "         \n",
    "        log_dir = os.path.abspath(\"/home/mnt/HOTOSM_data/log\")\n",
    "        checkpointdir = os.path.abspath(\"/home/mnt/HOTOSM_data/ray_checkpoints\")\n",
    "        loss_train = 0.0\n",
    "\n",
    "        for i, (imgs, labels) in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "            imgs = imgs.to(device = device, dtype = torch.float32)\n",
    "            labels = labels.to(device = device, dtype = torch.float32)\n",
    "\n",
    "            prediction = model(imgs)\n",
    "            loss = loss_fn(prediction.squeeze(0), labels.squeeze(0))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_train += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            global_step = epoch * len(train_loader) + i\n",
    "\n",
    "        # Validation\n",
    "        #if epoch % val_freq == 0:\n",
    "        #    \n",
    "        #    model = model.eval()\n",
    "        #    val_loss = 0.0\n",
    "\n",
    "        #    with torch.no_grad():\n",
    "        #        for i, (imgs, labels) in tqdm(enumerate(val_loader), total = len(val_loader)):\n",
    "        #            imgs = imgs.to(device = device, dtype = torch.float32)\n",
    "        #            labels = labels.to(device = device, dtype = torch.float32)\n",
    "\n",
    "        #            prediction = model(imgs)\n",
    "        #            val_loss += loss_fn(prediction.squeeze(0), labels.squeeze(0))\n",
    "        #            assert val_loss.requires_grad == False\n",
    "\n",
    "        if epoch % checkpoint_freq == 0:\n",
    "            with tune.checkpoint_dir(step = global_step) as checkpoint_dir:\n",
    "                checkpoint_dir = checkpointdir\n",
    "                os.makedirs(os.path.join(checkpoint_dir, xp_name), exist_ok = True)\n",
    "                checkpoint_file = os.path.join(checkpoint_dir, xp_name, xp_name + \"_iter_\" + str(global_step).zfill(6) + \".pth\")\n",
    "                model_state = {}\n",
    "\n",
    "                model_state = model.state_dict()\n",
    "\n",
    "                state = {\"Model:\": model_state, \"Epoch:\": epoch, \"Steps:\": global_step}\n",
    "                torch.save(state, checkpoint_file)\n",
    "\n",
    "            tune.report(loss = (loss_train / global_step))\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "\n",
    "###########################################\n",
    "###########################################\n",
    "###########################################\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, xp_name,\n",
    "                  loss_fn, in_channels, out_channels, train_loader,\n",
    "                  val_loader, val_freq, checkpoint_freq):\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "        \n",
    "        log_dir = os.path.abspath(\"/home/mnt/HOTOSM_data/log\")\n",
    "        checkpointdir = os.path.abspath(\"/home/mnt/HOTOSM_data/checkpoints\")\n",
    "        writer = SummaryWriter(os.path.join(log_dir, xp_name))\n",
    "\n",
    "        loss_train = 0.0\n",
    "\n",
    "        for i, (imgs, labels) in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "            imgs = imgs.to(device = device, dtype = torch.float32)\n",
    "            labels = labels.to(device = device, dtype = torch.float32)\n",
    "\n",
    "            prediction = model(imgs)\n",
    "            loss = loss_fn(prediction.squeeze(0), labels.squeeze(0))\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_train += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            global_step = epoch * len(train_loader) + i\n",
    "\n",
    "            if global_step % 10 == 0:\n",
    "                writer.add_scalar(\"Train/Loss\", loss.item(), global_step = global_step)\n",
    "                writer.add_scalar(\"Batch/Loss\", loss_train/len(train_loader), global_step = global_step)\n",
    "        # Validation\n",
    "\n",
    "        if epoch % val_freq == 0:\n",
    "            \n",
    "            model = model.eval()\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, (imgs, labels) in tqdm(enumerate(val_loader), total = len(val_loader)):\n",
    "                    imgs = imgs.to(device = device, dtype = torch.float32)\n",
    "                    labels = labels.to(device = device, dtype = torch.float32)\n",
    "\n",
    "                    prediction = model(imgs)\n",
    "                    val_loss += loss_fn(prediction.squeeze(0), labels.squeeze(0))\n",
    "                    assert val_loss.requires_grad == False\n",
    "\n",
    "#                    if i == 0:\n",
    "#                        writer.add_images(\"Val/Sample_LBL\", labels[:, :, :, :].squeeze(0), dataformats = \"CHW\",\n",
    "#                                          global_step = global_step)\n",
    "#\n",
    "#                        if out_channels > 1:\n",
    "#                            writer.add_images(\"Val/Sample_conf_1\", prediction[:, 0, :, :].squeeze(0), \n",
    "#                                              global_step = global_step, dataformats = \"CHW\")\n",
    "#                            writer.add_images(\"Val/Sample_conf_2\", prediction[:, 1, :, :].squeeze(0), \n",
    "#                                              global_step = global_step, dataformats = \"CHW\")\n",
    "#\n",
    "#                            confidence = prediction[:, 0, :, :] - prediction[:, 1, :, :]\n",
    "#                            writer.add_images(\"Val/Sample_conf\", confidence.squeeze(0), \n",
    "#                                              global_step = global_step, dataformats = \"CHW\")\n",
    "#\n",
    "#                            prediction = torch.argmax(prediction, 1).cpu().detach().numpy()\n",
    "#                        else:\n",
    "#                            writer.add_images(\"Val/Sample_conf\", confidence.squeeze(0), \n",
    "#                                              global_step = global_step, dataformats = \"CHW\")\n",
    "#\n",
    "#                            prediction = (torch.sigmoid(prediction) > 0.5)\n",
    "#\n",
    "#                        writer.add_images(\"Val/Sample_pred\", prediction.squeeze(0), \n",
    "#                                          global_step = global_step, dataformats = \"CHW\")\n",
    "#\n",
    "                writer.add_scalar(\"Val/Loss\", val_loss.item(), global_step = global_step)\n",
    "\n",
    "\n",
    "        if epoch % checkpoint_freq == 0:\n",
    "            os.makedirs(os.path.join(checkpointdir, xp_name), exist_ok = True)\n",
    "            checkpoint_file = os.path.join(checkpointdir, xp_name, xp_name + \"_iter_\" + str(global_step).zfill(6) + \".pth\")\n",
    "            model_state = {}\n",
    "\n",
    "            model_state = model.state_dict()\n",
    "\n",
    "            state = {\"Model:\": model_state, \"Epoch:\": epoch, \"Steps:\": global_step}\n",
    "            torch.save(state, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141acde1-7c7d-438f-bc83-aec86c900a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (encoder): EfficientNetEncoder(\n",
      "    (_conv_stem): Conv2dStaticSamePadding(\n",
      "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_blocks): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (1): MBConvBlock(\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (2): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (3): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (4): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (5): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (6): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (7): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (8): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (9): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (10): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (11): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (12): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (13): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (14): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (15): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (16): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (17): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (18): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (19): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (20): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (21): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (22): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1920, 1920, kernel_size=(3, 3), stride=(1, 1), groups=1920, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1920, 80, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          80, 1920, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "    )\n",
      "    (_conv_head): Conv2dStaticSamePadding(\n",
      "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "    (_dropout): Dropout(p=0.2, inplace=False)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(432, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(296, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(152, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable parameters in current model: [864, 32, 32, 288, 32, 32, 256, 8, 256, 32, 512, 16, 16, 144, 16, 16, 64, 4, 64, 16, 256, 16, 16, 1536, 96, 96, 864, 96, 96, 384, 4, 384, 96, 2304, 24, 24, 3456, 144, 144, 1296, 144, 144, 864, 6, 864, 144, 3456, 24, 24, 3456, 144, 144, 1296, 144, 144, 864, 6, 864, 144, 3456, 24, 24, 3456, 144, 144, 3600, 144, 144, 864, 6, 864, 144, 5760, 40, 40, 9600, 240, 240, 6000, 240, 240, 2400, 10, 2400, 240, 9600, 40, 40, 9600, 240, 240, 6000, 240, 240, 2400, 10, 2400, 240, 9600, 40, 40, 9600, 240, 240, 2160, 240, 240, 2400, 10, 2400, 240, 19200, 80, 80, 38400, 480, 480, 4320, 480, 480, 9600, 20, 9600, 480, 38400, 80, 80, 38400, 480, 480, 4320, 480, 480, 9600, 20, 9600, 480, 38400, 80, 80, 38400, 480, 480, 4320, 480, 480, 9600, 20, 9600, 480, 38400, 80, 80, 38400, 480, 480, 12000, 480, 480, 9600, 20, 9600, 480, 53760, 112, 112, 75264, 672, 672, 16800, 672, 672, 18816, 28, 18816, 672, 75264, 112, 112, 75264, 672, 672, 16800, 672, 672, 18816, 28, 18816, 672, 75264, 112, 112, 75264, 672, 672, 16800, 672, 672, 18816, 28, 18816, 672, 75264, 112, 112, 75264, 672, 672, 16800, 672, 672, 18816, 28, 18816, 672, 129024, 192, 192, 221184, 1152, 1152, 28800, 1152, 1152, 55296, 48, 55296, 1152, 221184, 192, 192, 221184, 1152, 1152, 28800, 1152, 1152, 55296, 48, 55296, 1152, 221184, 192, 192, 221184, 1152, 1152, 28800, 1152, 1152, 55296, 48, 55296, 1152, 221184, 192, 192, 221184, 1152, 1152, 28800, 1152, 1152, 55296, 48, 55296, 1152, 221184, 192, 192, 221184, 1152, 1152, 10368, 1152, 1152, 55296, 48, 55296, 1152, 368640, 320, 320, 614400, 1920, 1920, 17280, 1920, 1920, 153600, 80, 153600, 1920, 614400, 320, 320, 409600, 1280, 1280, 995328, 256, 256, 589824, 256, 256, 340992, 128, 128, 147456, 128, 128, 87552, 64, 64, 36864, 64, 64, 27648, 32, 32, 9216, 32, 32, 4608, 16, 16, 2304, 16, 16, 144, 1]\n"
     ]
    }
   ],
   "source": [
    "Net = smp.Unet(encoder_name = 'efficientnet-b1', encoder_depth = 5, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=1, activation=\"sigmoid\", aux_params=None)\n",
    "qubvel_weights = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/qubvel_UNet/weights/stage3/effb1-f0/checkpoints/best.pth\")\n",
    "qubvel_weights = torch.load(qubvel_weights, map_location = device)\n",
    "Net.load_state_dict(qubvel_weights[\"state_dict\"])\n",
    "\n",
    "#Net = smp.Unet(encoder_name='efficientnet-b1', encoder_depth = 4, encoder_weights = \"imagenet\", decoder_use_batchnorm = True, decoder_channels=(128, 64, 32, 16), decoder_attention_type = None, in_channels= 3 , classes = 1, activation = \"sigmoid\", aux_params = None)\n",
    "\n",
    "#Net = Four_UNet()\n",
    "\n",
    "#Net = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "\n",
    "Net = Net.to(device = device)\n",
    "\n",
    "n_params = [p.numel() for p in Net.parameters() if p.requires_grad == True]\n",
    "\n",
    "print(Net)\n",
    "print('Trainable parameters in current model:', n_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93dd09",
   "metadata": {},
   "source": [
    "### RayTune Hyperparameter Optimisation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35920f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 592/592 [04:00<00:00,  2.46it/s]\n",
      "100%|██████████| 592/592 [04:02<00:00,  2.44it/s]\n",
      "100%|██████████| 592/592 [03:56<00:00,  2.50it/s]\n",
      "Session not detected. You should not be calling `checkpoint_dir` outside `tune.run` or while using the class API. \n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24988/3430916723.py\", line 45, in <module>\n",
      "    main()\n",
      "  File \"/tmp/ipykernel_24988/3430916723.py\", line 22, in main\n",
      "    Loop = rayHPO_loop(n_epochs = max_epochs,\n",
      "  File \"/tmp/ipykernel_24988/1266474922.py\", line 44, in rayHPO_loop\n",
      "    with tune.checkpoint_dir(step = global_step) as checkpoint_dir:\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/contextlib.py\", line 119, in __enter__\n",
      "    return next(self.gen)\n",
      "\n",
      "Session not detected. You should not be calling `report` outside `tune.run` or while using the class API. \n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/chris/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_24988/3430916723.py\", line 45, in <module>\n",
      "    main()\n",
      "  File \"/tmp/ipykernel_24988/3430916723.py\", line 22, in main\n",
      "    Loop = rayHPO_loop(n_epochs = max_epochs,\n",
      "  File \"/tmp/ipykernel_24988/1266474922.py\", line 55, in rayHPO_loop\n",
      "    tune.report(loss = (loss_train / global_step))\n",
      "\n",
      "100%|██████████| 592/592 [03:52<00:00,  2.55it/s]\n",
      "100%|██████████| 592/592 [03:52<00:00,  2.55it/s]\n",
      "100%|██████████| 592/592 [03:54<00:00,  2.53it/s]\n",
      "100%|██████████| 592/592 [03:53<00:00,  2.54it/s]\n",
      "100%|██████████| 592/592 [03:52<00:00,  2.55it/s]\n",
      "100%|██████████| 592/592 [03:51<00:00,  2.55it/s]\n",
      "100%|██████████| 592/592 [03:53<00:00,  2.54it/s]\n",
      "100%|██████████| 592/592 [03:54<00:00,  2.53it/s]\n",
      "100%|██████████| 592/592 [03:53<00:00,  2.53it/s]\n",
      "100%|██████████| 592/592 [03:53<00:00,  2.53it/s]\n",
      "100%|██████████| 592/592 [03:53<00:00,  2.53it/s]\n",
      "100%|██████████| 592/592 [03:52<00:00,  2.55it/s]\n",
      "100%|██████████| 15/15 [58:37<00:00, 234.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`tune.with_parameters() only works with function trainables or classes that inherit from `tune.Trainable()`. Got type: <class 'NoneType'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24988/3430916723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24988/3430916723.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     30\u001b[0m                        checkpoint_freq = 3)\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     result = tune.run(tune.with_parameters(Loop,\n\u001b[0m\u001b[1;32m     33\u001b[0m                                            \u001b[0mresources_per_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                            \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/ray/tune/utils/trainable.py\u001b[0m in \u001b[0;36mwith_parameters\u001b[0;34m(trainable, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m     if not callable(trainable) or (inspect.isclass(trainable)\n\u001b[1;32m    298\u001b[0m                                    and not issubclass(trainable, Trainable)):\n\u001b[0;32m--> 299\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0;34mf\"`tune.with_parameters() only works with function trainables \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;34mf\"or classes that inherit from `tune.Trainable()`. Got type: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `tune.with_parameters() only works with function trainables or classes that inherit from `tune.Trainable()`. Got type: <class 'NoneType'>."
     ]
    }
   ],
   "source": [
    "# Ray tune Hyperparameter Optimsisation experiment using RayHPO_loop\n",
    "xp_name = \"2368:1184oc1_EB1-UNet-IMN_RAY_HYPERBANDBOHB_ep100_BCE\"\n",
    "\n",
    "config = {\"lr\": np.exp(np.random.uniform(1e-5, 1e-2)),\n",
    "          \"wd\": np.exp(np.random.uniform(1e-6, 1e-2)),\n",
    "          \"batch_size\": int(np.random.choice([4, 6]))}\n",
    "\n",
    "#config = {\"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "#          \"wd\": tune.loguniform(1e-6, 1e-2),\n",
    "#          \"batch_size\": tune.choice([4, 6])}\n",
    "\n",
    "def main(num_samples = 30, max_epochs = 15, gpus_per_trial = 1):\n",
    "\n",
    "    search_algo = TuneBOHB(mode = \"min\",\n",
    "                           metric = \"mean_loss\")\n",
    "\n",
    "    scheduler = HyperBandForBOHB(time_attr = \"training_iteration\",\n",
    "                                 metric = \"mean_loss\",\n",
    "                                 mode = \"min\",\n",
    "                                 max_t = max_epochs)\n",
    "    \n",
    "    Loop = rayHPO_loop(n_epochs = max_epochs, \n",
    "                       optimizer = torch.optim.Adam(Net.parameters(), lr = config[\"lr\"], weight_decay = config[\"wd\"]),\n",
    "                       model = Net,\n",
    "                       in_channels = 3,\n",
    "                       out_channels = 1,\n",
    "                       xp_name = xp_name,\n",
    "                       loss_fn = nn.BCELoss(reduction = 'mean'),\n",
    "                       train_loader = DataLoader(Train, batch_size = config[\"batch_size\"], shuffle = True),\n",
    "                       checkpoint_freq = 3)\n",
    "\n",
    "    result = tune.run(tune.with_parameters(Loop,\n",
    "                                           resources_per_trial = {\"cpu\": 4, \"gpu\": gpus_per_trial},\n",
    "                                           config = config,\n",
    "                                           num_samples = num_samples,\n",
    "                                           search_alg = search_algo,\n",
    "                                           scheduler = scheduler))\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "    \n",
    "    return best_trial\n",
    "\n",
    "main()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60c9f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24988/2665083351.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_trial' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098875cb-a2b4-4309-9d6c-a2976f7a88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp_name = \"2368:1184oc1_qubvel-UNet_lr5e-3_wd1e-5_b6_ep500_BCE\"\n",
    "\n",
    "training_loop(n_epochs = 500,\n",
    "              optimizer = torch.optim.Adam(Net.parameters(), lr = 5e-3, weight_decay = 1e-5),\n",
    "              model = Net,\n",
    "              in_channels = 3,\n",
    "              out_channels = 1,\n",
    "              xp_name = xp_name,\n",
    "              loss_fn = nn.BCELoss(reduction = 'mean'),\n",
    "              train_loader = DataLoader(Train, batch_size = 6, shuffle = True),\n",
    "              val_loader = DataLoader(Val, batch_size = 6 , shuffle = True),\n",
    "              checkpoint_freq = 10,\n",
    "              val_freq = 10)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "561a2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d1d48",
   "metadata": {},
   "source": [
    "## Prediction on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a sample\n",
    "test_pair = random.choice(Test)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "RGB = plt.imshow(test_pair[0].detach().cpu().numpy().transpose(1, 2, 0))\n",
    "ax.set_title('RGB')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "LBL = plt.imshow(test_pair[1].detach().cpu().numpy().transpose(1, 2, 0))\n",
    "ax.set_title('LBL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1fd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp_name = \"2368:1184oc1_EB1-UNet-IMN_lr1e-3_wd1e-5_b8_ep500_BCE\"\n",
    "\n",
    "Net = smp.Unet(encoder_name = 'efficientnet-b1', encoder_depth = 4, encoder_weights=None, decoder_use_batchnorm=True, decoder_channels=(128, 64, 32, 16), decoder_attention_type=None, in_channels=3, classes=1, activation=\"sigmoid\", aux_params=None)\n",
    "checkpoint_dir = os.path.abspath(\"/home/mnt/HOTOSM_data/checkpoints\")\n",
    "NN_weights = os.path.join(checkpoint_dir, xp_name, \"2368:1184oc1_EB1-UNet-IMN_lr1e-3_wd1e-5_b8_ep500_BCE_iter_100935.pth\")\n",
    "NN_weights = torch.load(NN_weights, map_location = device)\n",
    "\n",
    "Net.load_state_dict(NN_weights[\"Model:\"])\n",
    "Net.to(device = \"cpu\")\n",
    "Net.eval()\n",
    "\n",
    "img, lbl = test_pair[0], test_pair[1]\n",
    "img = img.to(device = \"cpu\")\n",
    "lbl = lbl.to(device = \"cpu\")\n",
    "print(img.shape, lbl.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = Net(img.unsqueeze(0))\n",
    "    prediction = prediction.squeeze(0)\n",
    "\n",
    "    print(prediction.shape)\n",
    "\n",
    "    pred_BOOL = (prediction > 0.5).to(torch.float32)\n",
    "\n",
    "    # Dice Loss\n",
    "    dice_pred = pred_BOOL.sum(dim = [0, 1, 2])\n",
    "    dice_lbl = lbl.sum(dim = [0, 1, 2])\n",
    "    dice_score = 0\n",
    "    dice_score += (2 * (pred_BOOL * lbl).sum(dim = [0, 1, 2]) + 1e-8) / (dice_pred + dice_lbl + 1e-8)\n",
    "    dice_score = dice_score.detach().cpu().numpy()\n",
    "\n",
    "    # True-Positive, True-Negative, False-Positive\n",
    "    TP = (pred_BOOL * lbl).sum(dim = [0, 1, 2])\n",
    "    FN = ((1 - pred_BOOL) * lbl).sum(dim = [0, 1, 2])\n",
    "    FP = (pred_BOOL * (1 - lbl)).sum(dim = [0, 1, 2])\n",
    "    IoU = (TP / (TP + FN + FP))\n",
    "\n",
    "print(\"True Positive = {0}, False Negative = {1}, False Positive = {2}, IoU = {3}\".format(TP, FN, FP, IoU))\n",
    "\n",
    "# Plotting the RGB, Prediction, and Confidence\n",
    "fig = plt.figure(figsize = (15, 6))\n",
    "ax = fig.add_subplot(1, 4, 1)\n",
    "fig.tight_layout(w_pad = 3)\n",
    "fig.suptitle(\"EfficientNet-B1 U-Net ImageNet (transfer-untuned) | Dice Score: {0}\".format(dice_score))\n",
    "RGB = plt.imshow(test_pair[0].detach().cpu().numpy().transpose(1, 2, 0))\n",
    "ax.set_title('RGB')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 2)\n",
    "PILlbl = lbl.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "plt.imshow(PILlbl)\n",
    "ax.set_title('Label')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 3)\n",
    "PILpred = prediction.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "plt.imshow(PILpred, cmap = \"brg\")\n",
    "plt.colorbar(boundaries = np.arange(0.5, 1.0, 0.1), ticks = np.arange(0.5, 1.0, 0.1),\n",
    "             orientation = \"horizontal\")\n",
    "ax.set_title('Prediction')\n",
    "\n",
    "ax = fig.add_subplot(1, 4, 4)\n",
    "PILbin = pred_BOOL.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "plt.imshow(PILbin, cmap = \"hot\")\n",
    "ax.set_title('Binary Segmentation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a437ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading testing batch\n",
    "test_loader = DataLoader(Test, batch_size = 1, shuffle = True)\n",
    "Net.to(device = device)\n",
    "\n",
    "idx = []\n",
    "Dice_ls = []\n",
    "TP_ls = []\n",
    "FN_ls = []\n",
    "FP_ls = []\n",
    "IoU_ls = []\n",
    "\n",
    "for i, (img, lbl) in tqdm(enumerate(test_loader)):\n",
    "    img = img.to(device = device)\n",
    "    lbl = lbl.to(device = device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = Net(img)\n",
    "        prediction = prediction.squeeze(0)\n",
    "        lbl = lbl.squeeze(0)\n",
    "\n",
    "        pred_BOOL = (prediction[:, 0:1] > 0.5).to(torch.float32)\n",
    "\n",
    "        # Dice Loss\n",
    " # Dice Loss\n",
    "        dice_pred = pred_BOOL.sum(dim = [0, 1, 2])\n",
    "        dice_lbl = lbl.sum(dim = [0, 1, 2])\n",
    "        dice_score = 0\n",
    "        dice_score += (2 * (pred_BOOL * lbl).sum(dim = [0, 1, 2]) + 1e-8) / (dice_pred + dice_lbl + 1e-8)\n",
    "        dice_score = dice_score.detach().cpu().numpy()\n",
    "        Dice_ls.append(dice_score)\n",
    "\n",
    "        # True-Positive, True-Negative, False-Positive\n",
    "        \n",
    "        TP = (pred_BOOL * lbl).sum(dim = [0, 1, 2])\n",
    "        FN = ((1 - pred_BOOL) * lbl).sum(dim = [0, 1, 2])\n",
    "        FP = (pred_BOOL * (1 - lbl)).sum(dim = [0, 1, 2])\n",
    "        IoU = (TP / (TP + FN + FP))\n",
    "\n",
    "        TP = TP.detach().cpu().numpy()\n",
    "        FN = FN.detach().cpu().numpy()\n",
    "        FP = FP.detach().cpu().numpy()\n",
    "        IoU = IoU.detach().cpu().numpy()\n",
    "        \n",
    "        idx.append(i)\n",
    "        TP_ls.append(TP)\n",
    "        FN_ls.append(FN)\n",
    "        FP_ls.append(FP)\n",
    "        IoU_ls.append(IoU)\n",
    "\n",
    "df = {\"id\": idx,\n",
    "      \"Dice_score\": Dice_ls,\n",
    "      \"True_Positive\": TP_ls,\n",
    "      \"False_Negative\": FN_ls,\n",
    "      \"False_Positive\": FP_ls,\n",
    "      \"IoU\": IoU_ls}\n",
    "      \n",
    "results_csv = pd.DataFrame(df)\n",
    "#print(\"mean True Positive = {0}, mean False Negative = {1}, mean False Positive = {2}, mean IoU = {3}\".format(np.mean(TP_ls), np.mean(FN_ls), np.mean(FP_ls), np.mean(IoU_ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c022f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_csv.info(), results_csv[\"Dice_score\"].describe(), results_csv.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
