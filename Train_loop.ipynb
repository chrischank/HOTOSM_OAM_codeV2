{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994b046f-e5e7-48c9-9afd-a510f864b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#Training loop for NNs       #\n",
    "#Maintainer: Christopher Chan#\n",
    "#Version: 0.0.5              #\n",
    "#Date: 2022-02-15            #\n",
    "##############################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pathlib\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch import optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Networks import Five_UNet\n",
    "from dataloader import BuildingDataset\n",
    "\n",
    "device = (torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "          else torch.device(\"cpu\"))\n",
    "\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba42bb2-e3e5-4b82-8757-2c591377fa0c",
   "metadata": {},
   "source": [
    "### Train Val Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cfbd46-14a4-46d0-955c-8bcb85c3d3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the selected dataset of td_DZK, There are: 6 images, 10 labels, and 6 matching image/label pairs.\n",
      "For the selected dataset of td_DZK, There are: 3 images, 10 labels, and 3 matching image/label pairs.\n",
      "For the selected dataset of td_DZK, There are: 1 images, 10 labels, and 1 matching image/label pairs.\n",
      "For the selected dataset of td_DZKN, There are: 6 images, 10 labels, and 6 matching image/label pairs.\n",
      "For the selected dataset of td_DZKN, There are: 3 images, 10 labels, and 3 matching image/label pairs.\n",
      "For the selected dataset of td_DZKN, There are: 1 images, 10 labels, and 1 matching image/label pairs.\n",
      "For the selected dataset of td_KBY, There are: 6 images, 10 labels, and 6 matching image/label pairs.\n",
      "For the selected dataset of td_KBY, There are: 3 images, 10 labels, and 3 matching image/label pairs.\n",
      "For the selected dataset of td_KBY, There are: 1 images, 10 labels, and 1 matching image/label pairs.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2867605/2266284613.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m Train = BuildingDataset(png_dir = (DZK_train + KBY_train + DZKN_train),\n\u001b[0;32m---> 97\u001b[0;31m                         lbl_dir = (DZKLBL_Train + KBYLBL_Train + DZKNLBL_Train))\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m Val = BuildingDataset(png_dir = (DZK_val + KBY_val + DZKN_val),\n",
      "\u001b[0;32m~/miniconda3/envs/HOTOSM_cpu/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Dataset[T_co]'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'ConcatDataset[T_co]'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# No `def __len__(self)` default?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HOTOSM_cpu/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, datasets)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterableDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ConcatDataset does not support IterableDataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HOTOSM_cpu/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36mcumsum\u001b[0;34m(sequence)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "td_KBY = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY\")\n",
    "td_DZK = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK\")\n",
    "td_DZKN = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN\")\n",
    "\n",
    "#td_KBY = os.path.abspath(\"/home/mnt/HOTOSM_data/Kakuma/Kalobeyei/td_KBY\")\n",
    "#td_DZK = os.path.abspath(\"/home/mnt/HOTOSM_data/Dzaleka/td_DZK\")\n",
    "#td_DZKN = os.path.abspath(\"/home/mnt/HOTOSM_data/Dzaleka_N/td_DZKN\")\n",
    "#\n",
    "# Below is a set of relatively complex functions which:\n",
    "# Perform the train, val, test split at a rounded ratio of 62%, 27%, and 10% based on each sets of imagery\n",
    "# This will be followed by first pseudo changing the name of _LBL_ to _IMG_ to match the split imagery\n",
    "# Lastly, once the correct LBL files are matched, \n",
    "\n",
    "def tvt_split(td):\n",
    "    \n",
    "    img_ls = []\n",
    "    \n",
    "    for root, dirs, filename in os.walk(os.path.join(td, \"IMG\")):\n",
    "        for i in filename:\n",
    "            if i.endswith(\".png\"):\n",
    "                img_ls.append(root + \"/\" + i)\n",
    "        \n",
    "        img_ls = BuildingDataset(img_ls, _)\n",
    "        \n",
    "        train_IMG, val_IMG, test_IMG = random_split(img_ls.png_dir, [int(round(0.6 * len(img_ls.png_dir))),\n",
    "                                                                     int(round(0.3 * len(img_ls.png_dir))),\n",
    "                                                                     int(round(0.1 * len(img_ls.png_dir)))])\n",
    "        \n",
    "        return train_IMG, val_IMG, test_IMG\n",
    "\n",
    "DZK_train, DZK_val, DZK_test = tvt_split(td_DZK)\n",
    "KBY_train, KBY_val, KBY_test = tvt_split(td_KBY)\n",
    "DZKN_train, DZKN_val, DZKN_test = tvt_split(td_DZKN)\n",
    "\n",
    "def match_LBL(td, imgs):\n",
    "    \n",
    "    lbl_ls = []\n",
    "    img_ls = []\n",
    "    match_ls = []\n",
    "    \n",
    "    imgs = list(imgs)\n",
    "    \n",
    "    for root, dirs, filename in os.walk(os.path.join(td, \"LBL\")):\n",
    "        for j in filename:\n",
    "            if j.endswith(\".png\"):\n",
    "                ps_name = j.rsplit(\"_LBL_\")[0] + \"_IMG_\" + j.rsplit(\"_LBL_\")[1] # Parse the string, PSEUDO-CHANGE _LBL_ to _IMG_\n",
    "                lbl_ls.append(ps_name)\n",
    "    \n",
    "    for k in imgs:\n",
    "        names = os.path.basename(k)\n",
    "        img_ls.append(names)\n",
    "        \n",
    "    def common(a, b):\n",
    "        a_set = set(a)\n",
    "        b_set = set(b)\n",
    "        if (a_set & b_set):\n",
    "            return (a_set & b_set)\n",
    "        else:\n",
    "            print(\"No common elements\")\n",
    "            \n",
    "            \n",
    "    match_ls = common(img_ls, lbl_ls)\n",
    "        \n",
    "    match_ls = [(root + \"/\" + n.replace(\"_IMG_\", \"_LBL_\")) for n in match_ls] # Change the _IMG_ back to _LBL_\n",
    "    \n",
    "    print(\"For the selected dataset of {0}, There are: {1} images, {2} labels, and {3} matching image/label pairs.\".format(os.path.basename(td), len(img_ls), len(lbl_ls), len(match_ls)))\n",
    "    \n",
    "    return match_ls\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Assign matched LBL to new LBL datasets#\n",
    "#########################################\n",
    "\n",
    "DZKLBL_Train = match_LBL(td_DZK, DZK_train)\n",
    "DZKLBL_Val = match_LBL(td_DZK, DZK_val)\n",
    "DZKLBL_Test = match_LBL(td_DZK, DZK_test)\n",
    "DZKNLBL_Train = match_LBL(td_DZKN, DZKN_train)\n",
    "DZKNLBL_Val = match_LBL(td_DZKN, DZKN_val)\n",
    "DZKNLBL_Test = match_LBL(td_DZKN, DZKN_test)\n",
    "KBYLBL_Train = match_LBL(td_KBY, KBY_train)\n",
    "KBYLBL_Val = match_LBL(td_KBY, KBY_val)\n",
    "KBYLBL_Test = match_LBL(td_KBY, KBY_test)\n",
    "\n",
    "DZKLBL_Train = BuildingDataset(_, [DZKLBL_Train])\n",
    "DZKLBL_Val = BuildingDataset(_, [DZKLBL_Val])\n",
    "DZKLBL_Test = BuildingDataset(_, [DZKLBL_Test])\n",
    "DZKNLBL_Train = BuildingDataset(_, [DZKNLBL_Train])\n",
    "DZKNLBL_Val = BuildingDataset(_, [DZKNLBL_Val])\n",
    "DZKNLBL_Test = BuildingDataset(_, [DZKNLBL_Test])\n",
    "KBYLBL_Train = BuildingDataset(_, [KBYLBL_Train])\n",
    "KBYLBL_Val = BuildingDataset(_, [KBYLBL_Val])\n",
    "KBYLBL_Test = BuildingDataset(_, [KBYLBL_Test])\n",
    "\n",
    "\n",
    "Train = BuildingDataset(png_dir = (DZK_train + KBY_train + DZKN_train),\n",
    "                        lbl_dir = (DZKLBL_Train + KBYLBL_Train + DZKNLBL_Train))\n",
    "\n",
    "Val = BuildingDataset(png_dir = (DZK_val + KBY_val + DZKN_val),\n",
    "                      lbl_dir = (DZKLBL_Val + KBYLBL_Val + DZKNLBL_Val))\n",
    "\n",
    "Test = BuildingDataset(png_dir = (DZK_test + KBY_test + DZKN_test),\n",
    "                       lbl_dir = (DZKLBL_Test + KBYLBL_Test + DZKNLBL_Test))\n",
    "\n",
    "print(len(Train.png_dir) == len(Train.lbl_dir))\n",
    "print(type(Train.png_dir), type(Train.lbl_dir))\n",
    "\n",
    "print(\"Total images and labels pair in DataLoader: {0}\".format(len(Train.png_dir) + len(Val.png_dir) + len(Test.png_dir)))\n",
    "\n",
    "print(\"Concatenated TRAINING images and labels pair: {0} :\".format(len(Train.png_dir)))\n",
    "for x, y in zip(Train.png_dir, Train.lbl_dir):    \n",
    "    print(f\"Image: {x}\", f\"Label: {y}\")\n",
    "\n",
    "print(\"Concatenated VALIDATION images and labels pair: {0} :\".format(len(Val.png_dir)))\n",
    "for x, y in zip(Val.png_dir, Val.lbl_dir):\n",
    "    print(f\"Image: {x}\", f\"Label: {y}\")\n",
    "\n",
    "print(\"Concatenated TESTING images: {0} and labels pair: {0} :\".format(len(Test.png_dir)))\n",
    "for x, y in zip(Test.png_dir, Test.lbl_dir):\n",
    "    print(f\"Image: {x}\", f\"Label: {y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "141acde1-7c7d-438f-bc83-aec86c900a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fe1ace6e760>\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(Train, batch_size = 1, shuffle = False)\n",
    "val_loader = DataLoader(Val, batch_size = 1, shuffle = False)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b4ce9e-31cb-4fd4-8b0f-f5ac0185d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7f7af0507d60>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(KBY_train.dataset.sort)\n",
    "\n",
    "print(KBY_train.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70913fd6-b994-4c97-a956-19106f200aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Five_UNet = Five_UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "207a9278-acb4-497e-93ec-d642d8dff053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device = device)\n",
    "            labels = labels.to(device = device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(\"{} Epoch {}, Training loss {}\".format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train/len(train_loader)))\n",
    "\n",
    "train_loader = DataLoader(Train, batch_size = 1, shuffle = False)\n",
    "val_loader = DataLoader(Val, batch_size = 1, shuffle = False)\n",
    "\n",
    "model = Five_UNet\n",
    "model.to(device = device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim = 1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "098875cb-a2b4-4309-9d6c-a2976f7a88fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14251/999260691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_loop(n_epochs = 100,\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               train_loader = train_loader)\n",
      "\u001b[0;32m/tmp/ipykernel_14251/1495215220.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, loss_fn, train_loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs = 100,\n",
    "              optimizer = optimizer,\n",
    "              model = model,\n",
    "              loss_fn = loss_fn,\n",
    "              train_loader = train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
