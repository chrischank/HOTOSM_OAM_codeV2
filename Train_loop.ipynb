{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994b046f-e5e7-48c9-9afd-a510f864b5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#Training loop for NNs       #\n",
    "#Maintainer: Christopher Chan#\n",
    "#Version: 0.0.6              #\n",
    "#Date: 2022-02-17            #\n",
    "##############################\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pathlib\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Networks import Five_UNet\n",
    "from dataloader import BuildingDataset\n",
    "\n",
    "device = (torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "          else torch.device(\"cpu\"))\n",
    "\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba42bb2-e3e5-4b82-8757-2c591377fa0c",
   "metadata": {},
   "source": [
    "### Train Val Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2cfbd46-14a4-46d0-955c-8bcb85c3d3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'list'> <class 'list'>\n",
      "Total images and labels pair in DataLoader: 30\n",
      "Concatenated TRAINING images and labels pair: 18 :\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1364-5456.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1364-5456.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1705-4774.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1705-4774.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1364-5797.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1364-5797.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1364-6138.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1364-6138.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1364-11594.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1364-11594.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1705-4433.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1705-4433.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2387-26939.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2387-26939.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2046-27621.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2046-27621.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2387-27621.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2387-27621.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2387-25234.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2387-25234.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2387-27962.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2387-27962.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2046-28303.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2046-28303.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_0-9889.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_0-9889.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_682-9548.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_682-9548.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_341-9548.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_341-9548.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_1023-10230.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_1023-10230.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_0-9548.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_0-9548.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_682-10230.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_682-10230.png\n",
      "Concatenated VALIDATION images and labels pair: 9 :\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1705-5456.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1705-5456.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1705-5115.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1705-5115.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1705-5797.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1705-5797.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2046-27962.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2046-27962.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2728-25234.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2728-25234.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2387-25575.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2387-25575.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_1023-9889.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_1023-9889.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_682-9889.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_682-9889.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_341-9889.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_341-9889.png\n",
      "Concatenated TESTING images: 3 and labels pair: 3 :\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1705-6138.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/LBL/DZK_LBL_1705-6138.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/IMG/KBY_IMG_2387-28303.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY/LBL/KBY_LBL_2387-28303.png\n",
      "Image: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/IMG/DZKN_IMG_682-10571.png Label: /home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN/LBL/DZKN_LBL_682-10571.png\n"
     ]
    }
   ],
   "source": [
    "td_KBY = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_KBY\")\n",
    "td_DZK = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK\")\n",
    "td_DZKN = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/SAMPLE/td_DZKN\")\n",
    "\n",
    "#td_KBY = os.path.abspath(\"/home/mnt/HOTOSM_data/Kakuma/Kalobeyei/td_KBY\")\n",
    "#td_DZK = os.path.abspath(\"/home/mnt/HOTOSM_data/Dzaleka/td_DZK\")\n",
    "#td_DZKN = os.path.abspath(\"/home/mnt/HOTOSM_data/Dzaleka_N/td_DZKN\")\n",
    "#\n",
    "# Below is a set of relatively complex functions which:\n",
    "# Perform the train, val, test split at a rounded ratio of 62%, 27%, and 10% based on each sets of imagery\n",
    "# This will be followed by first pseudo changing the name of _LBL_ to _IMG_ to match the split imagery\n",
    "# Lastly, once the correct LBL files are matched, \n",
    "\n",
    "def tvt_split(td):\n",
    "    \n",
    "    img_ls = []\n",
    "    \n",
    "    for root, dirs, filename in os.walk(os.path.join(td, \"IMG\")):\n",
    "        for i in filename:\n",
    "            if i.endswith(\".png\"):\n",
    "                img_ls.append(root + \"/\" + i)\n",
    "        \n",
    "        img_ls = BuildingDataset(img_ls, _)\n",
    "        \n",
    "        train_IMG, val_IMG, test_IMG = random_split(img_ls.png_dir, [int(round(0.6 * len(img_ls.png_dir))),\n",
    "                                                                     int(round(0.3 * len(img_ls.png_dir))),\n",
    "                                                                     int(round(0.1 * len(img_ls.png_dir)))])\n",
    "        \n",
    "        return train_IMG, val_IMG, test_IMG\n",
    "\n",
    "DZK_train, DZK_val, DZK_test = tvt_split(td_DZK)\n",
    "KBY_train, KBY_val, KBY_test = tvt_split(td_KBY)\n",
    "DZKN_train, DZKN_val, DZKN_test = tvt_split(td_DZKN)\n",
    "\n",
    "##################\n",
    "# TOO COMPLICATED#\n",
    "##################\n",
    "\n",
    "#def match_LBL(td, imgs):\n",
    "#    \n",
    "#    lbl_ls = []\n",
    "#    img_ls = []\n",
    "#    match_ls = []\n",
    "#    \n",
    "#    imgs = list(imgs)\n",
    "#    \n",
    "#    for root, dirs, filename in os.walk(os.path.join(td, \"LBL\")):\n",
    "#        for j in filename:\n",
    "#            if j.endswith(\".png\"):\n",
    "#                ps_name = j.rsplit(\"_LBL_\")[0] + \"_IMG_\" + j.rsplit(\"_LBL_\")[1] # Parse the string, PSEUDO-CHANGE _LBL_ to _IMG_\n",
    "#                lbl_ls.append(ps_name)\n",
    "#    \n",
    "#    for k in imgs:\n",
    "#        names = os.path.basename(k)\n",
    "#        img_ls.append(names)\n",
    "#        \n",
    "#    def common(a, b):\n",
    "#        a_set = set(a)\n",
    "#        b_set = set(b)\n",
    "#        if (a_set & b_set):\n",
    "#            return (a_set & b_set)\n",
    "#        else:\n",
    "#            print(\"No common elements\")\n",
    "#            \n",
    "#            \n",
    "#    match_ls = common(img_ls, lbl_ls)\n",
    "#        \n",
    "#    match_ls = [(root + \"/\" + n.replace(\"_IMG_\", \"_LBL_\")) for n in match_ls] # Change the _IMG_ back to _LBL_\n",
    "#    \n",
    "#    print(\"For the selected dataset of {0}, There are: {1} images, {2} labels, and {3} matching image/label pairs.\".format(os.path.basename(td), len(img_ls), len(lbl_ls), len(match_ls)))\n",
    "#    \n",
    "#    return match_ls\n",
    "\n",
    "#########################################\n",
    "# Assign matched LBL to new LBL datasets#\n",
    "#########################################\n",
    "\n",
    "#DZKLBL_Train = match_LBL(td_DZK, DZK_train)\n",
    "#DZKLBL_Val = match_LBL(td_DZK, DZK_val)\n",
    "#DZKLBL_Test = match_LBL(td_DZK, DZK_test)\n",
    "#DZKNLBL_Train = match_LBL(td_DZKN, DZKN_train)\n",
    "#DZKNLBL_Val = match_LBL(td_DZKN, DZKN_val)\n",
    "#DZKNLBL_Test = match_LBL(td_DZKN, DZKN_test)\n",
    "#KBYLBL_Train = match_LBL(td_KBY, KBY_train)\n",
    "#KBYLBL_Val = match_LBL(td_KBY, KBY_val)\n",
    "#KBYLBL_Test = match_LBL(td_KBY, KBY_test)\n",
    "\n",
    "############\n",
    "# Try again#\n",
    "############\n",
    "\n",
    "TrainLBL_ls = []\n",
    "ValLBL_ls = []\n",
    "TestLBL_ls = []\n",
    "\n",
    "TrainIMG_ls = list(DZK_train + KBY_train + DZKN_train)\n",
    "ValIMG_ls = list(DZK_val + KBY_val + DZKN_val)\n",
    "TestIMG_ls = list(DZK_test + KBY_test + DZKN_test)\n",
    "\n",
    "for i in TrainIMG_ls:\n",
    "    i = re.sub(\"IMG\", \"LBL\", i, count = 2)\n",
    "    TrainLBL_ls.append(i)\n",
    "\n",
    "for i in ValIMG_ls:\n",
    "    i = re.sub(\"IMG\", \"LBL\", i, count = 2)\n",
    "    ValLBL_ls.append(i)\n",
    "\n",
    "for i in TestIMG_ls:\n",
    "    i = re.sub(\"IMG\", \"LBL\", i, count = 2)\n",
    "    TestLBL_ls.append(i)\n",
    "\n",
    "Train = BuildingDataset(png_dir = TrainIMG_ls,\n",
    "                        lbl_dir = TrainLBL_ls)\n",
    "\n",
    "Val = BuildingDataset(png_dir = ValIMG_ls,\n",
    "                      lbl_dir = ValLBL_ls)\n",
    "\n",
    "Test = BuildingDataset(png_dir = TestIMG_ls,\n",
    "                       lbl_dir = TestLBL_ls)\n",
    "\n",
    "print(len(Train.png_dir) == len(Train.lbl_dir))\n",
    "print(type(Train.png_dir), type(Train.lbl_dir))\n",
    "\n",
    "print(\"Total images and labels pair in DataLoader: {0}\".format(len(Train.png_dir) + len(Val.png_dir) + len(Test.png_dir)))\n",
    "\n",
    "print(\"Concatenated TRAINING images and labels pair: {0} :\".format(len(Train.png_dir)))\n",
    "for x, y in zip(Train.png_dir, Train.lbl_dir):    \n",
    "    print(f\"Image: {x}\", f\"Label: {y}\")\n",
    "\n",
    "print(\"Concatenated VALIDATION images and labels pair: {0} :\".format(len(Val.png_dir)))\n",
    "for x, y in zip(Val.png_dir, Val.lbl_dir):\n",
    "    print(f\"Image: {x}\", f\"Label: {y}\")\n",
    "\n",
    "print(\"Concatenated TESTING images: {0} and labels pair: {0} :\".format(len(Test.png_dir)))\n",
    "for x, y in zip(Test.png_dir, Test.lbl_dir):\n",
    "    print(f\"Image: {x}\", f\"Label: {y}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a9278-acb4-497e-93ec-d642d8dff053",
   "metadata": {},
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device = device)\n",
    "            labels = labels.to(device = device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(\"{} Epoch {}, Training loss {}\".format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train/len(train_loader)))\n",
    "\n",
    "train_loader = DataLoader(Train, batch_size = 1, shuffle = False)\n",
    "val_loader = DataLoader(Val, batch_size = 1, shuffle = False)\n",
    "\n",
    "model = Five_UNet\n",
    "model.to(device = device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim = 1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name, correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce4151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, xp_name, loss_fn, \n",
    "                  train_loader, val_loader, checkpoint_freq, val_freq):\n",
    "    for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "\n",
    "        model = model\n",
    "        \n",
    "        log_dir = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/log\")\n",
    "        checkpointdir = os.path.abspath(\"/home/chris/Dropbox/HOTOSM/checkpoints\")\n",
    "        writer = SummaryWriter(os.path.join(log_dir, xp_name))\n",
    "\n",
    "        for i, batch in tqdm(enumerate(train_loader), total = len(Train.png_dir)):\n",
    "            img = batch[\"png_dir\"].float32()\n",
    "            img = img.to(device = device)\n",
    "            lbl = batch[\"lbl_dir\"].float32()\n",
    "            lbl = lbl.to(device = device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            loss = loss_fn(prediction.squeeze(), target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step = epoch * len(train_loader) + i\n",
    "\n",
    "            if global_step % 10 == 0:\n",
    "                writer.add_scalar('train/loss', loss.item(), global_step=global_step)\n",
    "\n",
    "        val_loss = 0\n",
    "\n",
    "        if epoch % val_freq == 0:\n",
    "            with torch.no_grad():\n",
    "                for i, batch in tqdm(enumerate(val_loader), total = len(Val.png_dir)):\n",
    "\n",
    "                    img = batch['png_dir'].float32()\n",
    "                    img = img.to(device = device)\n",
    "                    lbl = batch['lbl_dir'].float32()\n",
    "                    lbl = lbl.to(device = device)\n",
    "\n",
    "                    prediction = model.squeeze()\n",
    "                    val_loss += loss_fn(prediction, target)\n",
    "\n",
    "                    if i == 0:\n",
    "                        writer.add_images('val/samples_img', img[:, 1:4, :, :] / img.max(), global_step = global_step)\n",
    "                        target = target.cpu().detach().numpy()\n",
    "                        writer.add_images('val/samples_lbl', np.rollaxis(target.astype(np.uint8), 3, 1), global_step = global_step)\n",
    "\n",
    "                        writer.add_images('val/samples_pred_conf', torch.sigmoid(prediction).unsqueeze(1), global_step = global_step)\n",
    "                        prediction = (torch.sigmoid(prediction).cpu().detach().numpy() > 0.5).astype(np.uint8)\n",
    "                        writer.add_images('val/samples_pred', np.rollaxis(prediction, 3, 1), global_step = global_step)\n",
    "\n",
    "                # print('val loss after epoch', epoch, '=', val_loss.item()/len(val_set))\n",
    "                writer.add_scalar('val/loss', val_loss.item(), global_step = global_step)\n",
    "\n",
    "        if epoch % checkpoint_freq == 0:\n",
    "            os.makedirs(os.path.join(checkpointdir, xp_name), exist_ok = True)\n",
    "            checkpoint_file = os.path.join(checkpointdir, xp_name, xp_name + '_iter_' + str(global_step).zfill(6) + '.pth')\n",
    "            model_states = {}\n",
    "            for model_id in model.keys():\n",
    "                model_states[model_id] = model[model_id].state_dict()\n",
    "            state = {'models': model_states, 'epoch': epoch, 'step': global_step}\n",
    "            torch.save(state, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141acde1-7c7d-438f-bc83-aec86c900a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five_UNet(\n",
      "  (encoder1): Sequential(\n",
      "    (enc1conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc1relu1): ReLU(inplace=True)\n",
      "    (enc1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc1relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder2): Sequential(\n",
      "    (enc2conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc2relu1): ReLU(inplace=True)\n",
      "    (enc2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc2relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder3): Sequential(\n",
      "    (enc3conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc3relu1): ReLU(inplace=True)\n",
      "    (enc3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc3relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder4): Sequential(\n",
      "    (enc4conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc4relu1): ReLU(inplace=True)\n",
      "    (enc4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc4relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder5): Sequential(\n",
      "    (enc5conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc5norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc5relu1): ReLU(inplace=True)\n",
      "    (enc5conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc5norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc5relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bottleneck): Sequential(\n",
      "    (bottleneckconv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bottlenecknorm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bottleneckrelu1): ReLU(inplace=True)\n",
      "    (bottleneckconv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bottlenecknorm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bottleneckrelu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upconv4): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder4): Sequential(\n",
      "    (dec4conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec4relu1): ReLU(inplace=True)\n",
      "    (dec4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec4relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder3): Sequential(\n",
      "    (dec3conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec3relu1): ReLU(inplace=True)\n",
      "    (dec3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec3relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upconv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder2): Sequential(\n",
      "    (dec2conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec2relu1): ReLU(inplace=True)\n",
      "    (dec2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec2relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upconv1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder1): Sequential(\n",
      "    (dec1conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec1relu1): ReLU(inplace=True)\n",
      "    (dec1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec1relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Trainable parameters in current model: [864, 32, 32, 9216, 32, 32, 18432, 64, 64, 36864, 64, 64, 73728, 128, 128, 147456, 128, 128, 294912, 256, 256, 589824, 256, 256, 1179648, 512, 512, 2359296, 512, 512, 4718592, 1024, 1024, 9437184, 1024, 1024, 2097152, 512, 1179648, 256, 256, 589824, 256, 256, 131072, 128, 294912, 128, 128, 147456, 128, 128, 32768, 64, 73728, 64, 64, 36864, 64, 64, 8192, 32, 18432, 32, 32, 9216, 32, 32, 64, 2]\n"
     ]
    }
   ],
   "source": [
    "Net = Five_UNet()\n",
    "\n",
    "n_params = [p.numel() for p in Net.parameters() if p.requires_grad == True]\n",
    "\n",
    "print(Net)\n",
    "print('Trainable parameters in current model:', n_params)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = DataLoader(Train, batch_size = 3, shuffle = False) \n",
    "val_loader = DataLoader(Val, batch_size = 3, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be48633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chris/Dropbox/HOTOSM/SAMPLE/td_DZK/IMG/DZK_IMG_1364-6138.png\n"
     ]
    }
   ],
   "source": [
    "    print(Train.png_dir[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098875cb-a2b4-4309-9d6c-a2976f7a88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26478/1928709497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_loop(n_epochs = 500,\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mxp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"18:9_Adam1e-3_wd1e-3_b1_ep100\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26478/2830564603.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(n_epochs, optimizer, model, xp_name, loss_fn, train_loader, val_loader, checkpoint_freq, val_freq)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpng_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"png_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/HOTOSM_gpu/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs = 500,\n",
    "              optimizer = torch.optim.Adam(Net.parameters(), lr = 1e-3, weight_decay = 1e-3),\n",
    "              model = Net,\n",
    "              xp_name = \"18:9_Adam1e-3_wd1e-3_b1_ep100\",\n",
    "              loss_fn = loss_fn,\n",
    "              train_loader = train_loader,\n",
    "              val_loader = val_loader,\n",
    "              checkpoint_freq = 10,\n",
    "              val_freq = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5654b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
